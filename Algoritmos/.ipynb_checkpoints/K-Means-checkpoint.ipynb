{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bac6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame, permitiendo la detección de tipo más precisa\n",
    "df = pd.read_csv('generadoras_activas_corregido.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc920e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Asegúrate de que las fechas en el DataFrame original estén en el formato datetime\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'])\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Preparar los datos para el clustering usando la columna 'TOTAL'\n",
    "X = energia_por_fecha[['TOTAL']]\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Determinar el número óptimo de clusters utilizando el método del codo\n",
    "wss = []\n",
    "k_values = range(1, 11)  # Probar de 1 a 20 clusters\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wss.append(kmeans.inertia_)\n",
    "\n",
    "# Imprimir los valores de WSS para cada k\n",
    "print('Valores de WSS para cada k:')\n",
    "for k, wss_value in zip(k_values, wss):\n",
    "    print(f'k = {k}: WSS = {wss_value:.2f}')\n",
    "\n",
    "# Graficar el WSS para encontrar el codo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, wss, marker='o')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Suma de errores cuadráticos dentro del cluster (WSS)')\n",
    "plt.title('Método del Codo para determinar el número óptimo de clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b38ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para calcular el Prediction Strength\n",
    "def prediction_strength(train_labels, val_labels, n_clusters):\n",
    "    \"\"\"Calcula el Prediction Strength ajustado para tamaños diferentes de conjuntos\"\"\"\n",
    "    def cluster_membership_matrix(labels, n_clusters):\n",
    "        n_samples = len(labels)\n",
    "        membership = np.zeros((n_samples, n_samples))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                if labels[i] == labels[j]:\n",
    "                    membership[i, j] = 1\n",
    "        return membership\n",
    "\n",
    "    # Obtener matrices de pertenencia\n",
    "    train_membership_matrix = cluster_membership_matrix(train_labels, n_clusters)\n",
    "    val_membership_matrix = cluster_membership_matrix(val_labels, n_clusters)\n",
    "    \n",
    "    total_pairs = 0\n",
    "    consistent_pairs = 0\n",
    "    \n",
    "    # Calcular consistencia para pares juntos y separados\n",
    "    for i in range(min(len(train_labels), len(val_labels))):\n",
    "        for j in range(i + 1, min(len(train_labels), len(val_labels))):\n",
    "            # Pares juntos en entrenamiento\n",
    "            if train_membership_matrix[i, j] == 1:\n",
    "                total_pairs += 1\n",
    "                if val_membership_matrix[i, j] == 1:\n",
    "                    consistent_pairs += 1\n",
    "            # Pares separados en entrenamiento\n",
    "            elif train_membership_matrix[i, j] == 0:\n",
    "                total_pairs += 1\n",
    "                if val_membership_matrix[i, j] == 0:\n",
    "                    consistent_pairs += 1\n",
    "\n",
    "    return consistent_pairs / total_pairs if total_pairs > 0 else 0\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Pivotar los datos para tener fechas como columnas y llaves como filas\n",
    "pivot_df = energia_por_fecha.pivot(index='LLAVE NOMBRE', columns='FECHA', values='TOTAL').fillna(0)\n",
    "\n",
    "# Convertir las columnas de fecha a datetime\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns)\n",
    "\n",
    "# Añadir la columna de nombres de generadoras al DataFrame\n",
    "pivot_df['LLAVE NOMBRE'] = pivot_df.index\n",
    "\n",
    "# Separar en 90% entrenamiento y 10% validación\n",
    "train_df, val_df = train_test_split(pivot_df, test_size=0.1, random_state=42, stratify=None)\n",
    "\n",
    "# Convertir los DataFrames de entrenamiento y validación a un formato adecuado para DTW\n",
    "train_data = train_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "val_data = val_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "\n",
    "# Normalización de series temporales\n",
    "scaler = TimeSeriesScalerMinMax()\n",
    "train_data_normalized = scaler.fit_transform(train_data.reshape((train_data.shape[0], train_data.shape[1], 1)))\n",
    "val_data_normalized = scaler.transform(val_data.reshape((val_data.shape[0], val_data.shape[1], 1)))\n",
    "\n",
    "# Lista para guardar los resultados de cada métrica\n",
    "results_euclidean = []\n",
    "results_dtw = []\n",
    "\n",
    "# Rango de valores para n_clusters\n",
    "n_clusters_range = range(2, 16)  \n",
    "\n",
    "# Probar con diferentes combinaciones de métrica y número de clústeres\n",
    "for metric in ['euclidean', 'dtw']:  # Ahora probamos tanto Euclidean como DTW\n",
    "    print(f\"Probando con métrica: {metric.upper()}\")\n",
    "\n",
    "    for n_clusters in n_clusters_range:\n",
    "        # Iniciar cronómetro\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Aplicar K-means en el conjunto de entrenamiento\n",
    "        model = TimeSeriesKMeans(n_clusters=n_clusters, metric=metric, random_state=0)\n",
    "        train_labels = model.fit_predict(train_data_normalized)\n",
    "\n",
    "        # Evaluar el modelo en el conjunto de validación\n",
    "        val_labels = model.predict(val_data_normalized)\n",
    "\n",
    "        # Calcular el Prediction Strength\n",
    "        ps_score = prediction_strength(train_labels, val_labels, n_clusters)\n",
    "\n",
    "        # Detener el cronómetro\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calcular el tiempo de ejecución\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        # Imprimir el valor de Prediction Strength y el tiempo de ejecución\n",
    "        print(f\"n_clusters = {n_clusters}, Prediction Strength = {ps_score:.2f}, Tiempo de ejecución = {execution_time:.2f} s\")\n",
    "\n",
    "        # Guardar los resultados para este valor de k\n",
    "        result = {\n",
    "            'k': n_clusters,\n",
    "            'Prediction Strength': ps_score,\n",
    "            'Execution Time (s)': execution_time\n",
    "        }\n",
    "        \n",
    "        # Almacenar resultados en el DataFrame correspondiente\n",
    "        if metric == 'euclidean':\n",
    "            results_euclidean.append(result)\n",
    "        else:\n",
    "            results_dtw.append(result)  # Ahora también guardamos los resultados de DTW\n",
    "\n",
    "# Convertir resultados a DataFrame para graficar\n",
    "df_euclidean = pd.DataFrame(results_euclidean)\n",
    "df_dtw = pd.DataFrame(results_dtw)\n",
    "\n",
    "# Graficar resultados para métrica Euclidean\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_euclidean['k'], df_euclidean['Prediction Strength'], label='Prediction Strength (Euclidean)', marker='o')\n",
    "plt.xlabel('Número de Clusters (K)')\n",
    "plt.ylabel('Prediction Strength')\n",
    "plt.title('Euclidean: Prediction Strength vs Número de Clusters')\n",
    "# Configurar el eje X para mostrar solo números enteros\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Verificar si hay resultados de DTW antes de graficar\n",
    "if not df_dtw.empty:\n",
    "    # Graficar resultados para métrica DTW\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df_dtw['k'], df_dtw['Prediction Strength'], label='Prediction Strength (DTW)', marker='o')\n",
    "    plt.xlabel('Número de Clusters (K)')\n",
    "    plt.ylabel('Prediction Strength')\n",
    "    plt.title('DTW: Prediction Strength vs Número de Clusters')\n",
    "    # Configurar el eje X para mostrar solo números enteros\n",
    "    plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay resultados para DTW.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a1014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir resultados a DataFrame para graficar\n",
    "df_euclidean = pd.DataFrame(results_euclidean)\n",
    "df_dtw = pd.DataFrame(results_dtw)\n",
    "\n",
    "# Graficar ambos resultados en una sola figura\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Graficar para Euclidean en azul\n",
    "plt.plot(df_euclidean['k'], df_euclidean['Prediction Strength'], label='Prediction Strength (Euclidean)', marker='o', color='blue')\n",
    "\n",
    "# Graficar para DTW en naranja si no está vacío\n",
    "if not df_dtw.empty:\n",
    "    plt.plot(df_dtw['k'], df_dtw['Prediction Strength'], label='Prediction Strength (DTW)', marker='o', color='orange')\n",
    "\n",
    "# Configuración de la gráfica\n",
    "plt.xlabel('Número de Clusters (K)')\n",
    "plt.ylabel('Prediction Strength')\n",
    "plt.title('Prediction Strength vs Número de Clusters para Euclidean y DTW')\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaf5391",
   "metadata": {},
   "source": [
    "1. Prediction Strength:\n",
    "La Prediction Strength mide la estabilidad del clustering. Buscamos un valor de k donde esta métrica sea alta (indica clusters consistentes).\n",
    "Los valores de Prediction Strength aumentan progresivamente y alcanzan un máximo en k = 19 con un valor de 0.90 para DTW y 0.84 para Euclidean.\n",
    "2. WSS (Suma de errores cuadráticos dentro del cluster):\n",
    "La métrica de WSS disminuye significativamente hasta k = 6. Después de este valor, la reducción en WSS es menos drástica, lo que sugiere que los beneficios adicionales de agregar más clusters se reducen.\n",
    "Esto significa que k = 6 es un buen punto de corte desde el punto de vista de WSS, ya que se logra una buena compactación de los clusters con una reducción significativa en la variabilidad intra-cluster.\n",
    "\n",
    "k = 6 es un buen valor considerando un equilibrio entre Prediction Strength, WSS, y tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff401e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import time\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Pivotar los datos para tener fechas como columnas y llaves como filas\n",
    "pivot_df = energia_por_fecha.pivot(index='LLAVE NOMBRE', columns='FECHA', values='TOTAL').fillna(0)\n",
    "\n",
    "# Convertir las columnas de fecha a datetime\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns)\n",
    "\n",
    "# Añadir la columna de nombres de generadoras al DataFrame\n",
    "pivot_df['LLAVE NOMBRE'] = pivot_df.index\n",
    "\n",
    "# Muestreo: seleccionar una fracción aleatoria de los datos (por ejemplo, el 10%)\n",
    "sample_df = pivot_df.sample(frac=1, random_state=0)  # Ajusta la fracción según sea necesario\n",
    "\n",
    "# Convertir el DataFrame muestreado a un formato adecuado\n",
    "data = sample_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "\n",
    "# Normalización específica de series temporales\n",
    "data_normalized = TimeSeriesScalerMinMax().fit_transform(data.reshape((data.shape[0], data.shape[1], 1)))\n",
    "\n",
    "# Empezar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Aplicar K-means usando la métrica euclidiana\n",
    "n_clusters = 6  # Ajusta el número de clusters según sea necesario\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"euclidean\", random_state=0)\n",
    "labels = model.fit_predict(data_normalized)\n",
    "\n",
    "# Añadir los resultados al DataFrame muestreado\n",
    "sample_df['Cluster'] = labels\n",
    "\n",
    "# Reordenar las columnas para mantener 'LLAVE NOMBRE' al principio\n",
    "sample_df = sample_df[['LLAVE NOMBRE', 'Cluster'] + [col for col in sample_df.columns if col not in ['LLAVE NOMBRE', 'Cluster']]]\n",
    "\n",
    "# Calcular la matriz de distancias euclidianas\n",
    "distances = pairwise_distances(data_normalized.reshape(data_normalized.shape[0], data_normalized.shape[1]))\n",
    "\n",
    "# Calcular el índice de Silueta usando la métrica euclidiana\n",
    "silhouette_avg = silhouette_score(distances, labels, metric='euclidean')\n",
    "\n",
    "# Detener el cronómetro\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
    "print(f\"Tiempo de ejecución: {execution_time / 60:.2f} minutos\")\n",
    "print(f\"Índice de Silueta: {silhouette_avg:.2f}\")\n",
    "\n",
    "# Limpiar las columnas de `pivot_df` asegurándose de que sean fechas\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns, errors='coerce')\n",
    "\n",
    "# Eliminar columnas que no se pudieron convertir a fechas\n",
    "pivot_df = pivot_df.loc[:, pivot_df.columns.notna()]\n",
    "\n",
    "# Obtener la lista de clusters únicos\n",
    "clusters = sample_df['Cluster'].unique()\n",
    "\n",
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'TIPO' de df\n",
    "tipo_df = df[['LLAVE NOMBRE', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de tipos por cluster\n",
    "totales_cluster = {}\n",
    "porcentaje_tipo_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada tipo\n",
    "total_tipos_df = tipo_df['TIPO'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_tipos_df.columns = ['TIPO', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener el tipo correspondiente para cada generadora\n",
    "    tipos = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada tipo\n",
    "    tipo_counts = tipos['TIPO'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = tipo_counts.sum()\n",
    "    totales_cluster[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada tipo dentro del cluster y agregar el conteo\n",
    "    tipo_porcentaje_y_cantidad = tipo_counts.to_frame(name='Cantidad')\n",
    "    tipo_porcentaje_y_cantidad['Porcentaje'] = (tipo_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_tipo_total[cluster] = tipo_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por tipo y por cluster\n",
    "print(\"Proporción total de cada tipo de generadora:\")\n",
    "print(total_tipos_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster:\")\n",
    "for cluster, total in totales_cluster.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por tipo en el cluster {cluster}:\")\n",
    "    print(porcentaje_tipo_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad\n",
    "\n",
    "# Calcular las series más cercanas al centroide para cada tipo dentro de cada cluster\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Filtrar las series temporales de las generadoras en el cluster\n",
    "    cluster_series = pivot_df.loc[generadoras]\n",
    "    \n",
    "    # Obtener los tipos de energía en el cluster\n",
    "    tipos_en_cluster = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Iterar sobre cada tipo de energía en el cluster\n",
    "    for tipo in tipos_en_cluster['TIPO'].unique():\n",
    "        # Filtrar las series temporales del tipo de energía actual\n",
    "        series_tipo = cluster_series.loc[tipos_en_cluster[tipos_en_cluster['TIPO'] == tipo]['LLAVE NOMBRE']]\n",
    "        \n",
    "        if not series_tipo.empty:\n",
    "            # Calcular el centroide (media) del tipo de energía\n",
    "            centroide = series_tipo.mean(axis=0)\n",
    "            \n",
    "            # Calcular la distancia entre cada serie temporal y el centroide usando la distancia euclidiana\n",
    "            distancias = np.array([np.linalg.norm(centroide.values - serie.values) for index, serie in series_tipo.iterrows()]).reshape(-1, 1)\n",
    "            \n",
    "            # Encontrar las 3 series más cercanas al centroide\n",
    "            indices_mas_cercanas = np.argsort(distancias, axis=0)[:3].flatten()\n",
    "            series_representativas = series_tipo.iloc[indices_mas_cercanas]\n",
    "            \n",
    "            # Graficar las 3 series temporales representativas\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            for j, (index, serie) in enumerate(series_representativas.iterrows()):\n",
    "                ax.plot(pivot_df.columns, serie, label=f'Cluster {cluster} - Tipo {tipo} - Serie {j+1}', linestyle='-', marker='o')\n",
    "            \n",
    "            # Configuración del gráfico\n",
    "            ax.set_title(f'Series Temporales Representativas del Cluster {cluster} - Tipo {tipo}')\n",
    "            ax.set_xlabel('Fecha')\n",
    "            ax.set_ylabel('Valor')\n",
    "            ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86115e1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Pivotar los datos para tener fechas como columnas y llaves como filas\n",
    "pivot_df = energia_por_fecha.pivot(index='LLAVE NOMBRE', columns='FECHA', values='TOTAL').fillna(0)\n",
    "\n",
    "# Convertir las columnas de fecha a datetime\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns)\n",
    "\n",
    "# Añadir la columna de nombres de generadoras al DataFrame\n",
    "pivot_df['LLAVE NOMBRE'] = pivot_df.index\n",
    "\n",
    "# Muestreo: seleccionar una fracción aleatoria de los datos (por ejemplo, el 10%)\n",
    "sample_df = pivot_df.sample(frac=1, random_state=0)  # Ajusta la fracción según sea necesario\n",
    "\n",
    "# Convertir el DataFrame muestreado a un formato adecuado\n",
    "data = sample_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "\n",
    "# Normalización específica de series temporales\n",
    "data_normalized = TimeSeriesScalerMinMax().fit_transform(data.reshape((data.shape[0], data.shape[1], 1)))\n",
    "\n",
    "# Empezar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Aplicar K-means usando la métrica euclidiana\n",
    "n_clusters = 6  # Ajusta el número de clusters según sea necesario\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"euclidean\", random_state=0)\n",
    "labels = model.fit_predict(data_normalized)\n",
    "\n",
    "# Añadir los resultados al DataFrame muestreado\n",
    "sample_df['Cluster'] = labels\n",
    "\n",
    "# Reordenar las columnas para mantener 'LLAVE NOMBRE' al principio\n",
    "sample_df = sample_df[['LLAVE NOMBRE', 'Cluster'] + [col for col in sample_df.columns if col not in ['LLAVE NOMBRE', 'Cluster']]]\n",
    "\n",
    "# Calcular la matriz de distancias euclidianas\n",
    "distances = pairwise_distances(data_normalized.reshape(data_normalized.shape[0], data_normalized.shape[1]))\n",
    "\n",
    "# Calcular el índice de Silueta usando la métrica euclidiana\n",
    "silhouette_avg = silhouette_score(distances, labels, metric='euclidean')\n",
    "\n",
    "# Detener el cronómetro\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
    "print(f\"Tiempo de ejecución: {execution_time / 60:.2f} minutos\")\n",
    "print(f\"Índice de Silueta: {silhouette_avg:.2f}\")\n",
    "\n",
    "# Visualización de los clústeres usando PCA\n",
    "data_reshaped = data_normalized.reshape(data_normalized.shape[0], -1)  # Convertir a 2D para PCA y t-SNE\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_reshaped)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in np.unique(labels):\n",
    "    plt.scatter(data_pca[labels == cluster, 0], data_pca[labels == cluster, 1], label=f'Cluster {cluster}')\n",
    "plt.title(\"Visualización de Clústeres usando PCA\")\n",
    "plt.xlabel(\"Componente Principal 1 (Varianza Máxima)\")\n",
    "plt.ylabel(\"Componente Principal 2 (Segunda Mayor Varianza)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualización de los clústeres usando t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=0)\n",
    "data_tsne = tsne.fit_transform(data_reshaped)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in np.unique(labels):\n",
    "    plt.scatter(data_tsne[labels == cluster, 0], data_tsne[labels == cluster, 1], label=f'Cluster {cluster}')\n",
    "plt.title(\"Visualización de Clústeres usando t-SNE\")\n",
    "plt.xlabel(\"Componente t-SNE 1\")\n",
    "plt.ylabel(\"Componente t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Limpiar las columnas de `pivot_df` asegurándose de que sean fechas\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns, errors='coerce')\n",
    "pivot_df = pivot_df.loc[:, pivot_df.columns.notna()]\n",
    "\n",
    "# Obtener la lista de clusters únicos\n",
    "clusters = sample_df['Cluster'].unique()\n",
    "\n",
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'TIPO' de df\n",
    "tipo_df = df[['LLAVE NOMBRE', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de tipos por cluster\n",
    "totales_cluster = {}\n",
    "porcentaje_tipo_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada tipo\n",
    "total_tipos_df = tipo_df['TIPO'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_tipos_df.columns = ['TIPO', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener el tipo correspondiente para cada generadora\n",
    "    tipos = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada tipo\n",
    "    tipo_counts = tipos['TIPO'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = tipo_counts.sum()\n",
    "    totales_cluster[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada tipo dentro del cluster y agregar el conteo\n",
    "    tipo_porcentaje_y_cantidad = tipo_counts.to_frame(name='Cantidad')\n",
    "    tipo_porcentaje_y_cantidad['Porcentaje'] = (tipo_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_tipo_total[cluster] = tipo_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por tipo y por cluster\n",
    "print(\"Proporción total de cada tipo de generadora:\")\n",
    "print(total_tipos_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster:\")\n",
    "for cluster, total in totales_cluster.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por tipo en el cluster {cluster}:\")\n",
    "    print(porcentaje_tipo_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad\n",
    "\n",
    "# Calcular las series más cercanas al centroide para cada tipo dentro de cada cluster\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Filtrar las series temporales de las generadoras en el cluster\n",
    "    cluster_series = pivot_df.loc[generadoras]\n",
    "    \n",
    "    # Obtener los tipos de energía en el cluster\n",
    "    tipos_en_cluster = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Iterar sobre cada tipo de energía en el cluster\n",
    "    for tipo in tipos_en_cluster['TIPO'].unique():\n",
    "        # Filtrar las series temporales del tipo de energía actual\n",
    "        series_tipo = cluster_series.loc[tipos_en_cluster[tipos_en_cluster['TIPO'] == tipo]['LLAVE NOMBRE']]\n",
    "        \n",
    "        if not series_tipo.empty:\n",
    "            # Calcular el centroide (media) del tipo de energía\n",
    "            centroide = series_tipo.mean(axis=0)\n",
    "            \n",
    "            # Calcular la distancia entre cada serie temporal y el centroide usando la distancia euclidiana\n",
    "            distancias = np.array([np.linalg.norm(centroide.values - serie.values) for index, serie in series_tipo.iterrows()]).reshape(-1, 1)\n",
    "            \n",
    "            # Encontrar las 3 series más cercanas al centroide\n",
    "            indices_mas_cercanas = np.argsort(distancias, axis=0)[:3].flatten()\n",
    "            series_representativas = series_tipo.iloc[indices_mas_cercanas]\n",
    "            \n",
    "            # Graficar las 3 series temporales representativas\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            for j, (index, serie) in enumerate(series_representativas.iterrows()):\n",
    "                ax.plot(pivot_df.columns, serie, label=f'Cluster {cluster} - Tipo {tipo} - Serie {j+1}', linestyle='-', marker='o')\n",
    "            \n",
    "            # Configuración del gráfico\n",
    "            ax.set_title(f'Series Temporales Representativas del Cluster {cluster} - Tipo {tipo}')\n",
    "            ax.set_xlabel('Fecha')\n",
    "            ax.set_ylabel('Valor')\n",
    "            ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759646f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'REGIÓN' de df\n",
    "region_df = df[['LLAVE NOMBRE', 'REGIÓN']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de regiones por cluster\n",
    "totales_cluster_region = {}\n",
    "porcentaje_region_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada región\n",
    "total_regiones_df = region_df['REGIÓN'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_regiones_df.columns = ['REGIÓN', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener la región correspondiente para cada generadora\n",
    "    regiones = region_df[region_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada región\n",
    "    region_counts = regiones['REGIÓN'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = region_counts.sum()\n",
    "    totales_cluster_region[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada región dentro del cluster y agregar el conteo\n",
    "    region_porcentaje_y_cantidad = region_counts.to_frame(name='Cantidad')\n",
    "    region_porcentaje_y_cantidad['Porcentaje'] = (region_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_region_total[cluster] = region_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por región y por cluster\n",
    "print(\"Proporción total de cada región de generadora:\")\n",
    "print(total_regiones_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster por región:\")\n",
    "for cluster, total in totales_cluster_region.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por región en el cluster {cluster}:\")\n",
    "    print(porcentaje_region_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3b576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las columnas 'LLAVE NOMBRE', 'REGIÓN' y 'TIPO' de df, eliminando duplicados\n",
    "region_tipo_df = df[['LLAVE NOMBRE', 'REGIÓN', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Diccionario para almacenar los totales y proporciones de tipos por región y cluster\n",
    "totales_cluster_region_tipo = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada región y tipo\n",
    "total_regiones_df = region_tipo_df.groupby(['REGIÓN', 'TIPO']).size().to_frame(name='Total').reset_index()\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones por región y tipo\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener la región y tipo correspondiente para cada generadora\n",
    "    regiones_tipos = region_tipo_df[region_tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada combinación de región y tipo\n",
    "    region_tipo_counts = regiones_tipos.groupby(['REGIÓN', 'TIPO']).size().to_frame(name='Cantidad').reset_index()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = region_tipo_counts['Cantidad'].sum()\n",
    "    \n",
    "    # Calcular el porcentaje de cada combinación de región y tipo dentro del cluster\n",
    "    region_tipo_counts['Porcentaje'] = (region_tipo_counts['Cantidad'] / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los resultados en el diccionario\n",
    "    totales_cluster_region_tipo[cluster] = region_tipo_counts\n",
    "\n",
    "# Mostrar los resultados totales por región y tipo en cada cluster\n",
    "print(\"Totales, cantidades y porcentajes de cada combinación de región y tipo por cluster:\")\n",
    "for cluster, data in totales_cluster_region_tipo.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras:\")\n",
    "    print(data)\n",
    "    print()  # Línea en blanco para mayor legibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c92a2f",
   "metadata": {},
   "source": [
    "# DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657c655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Pivotar los datos para tener fechas como columnas y llaves como filas\n",
    "pivot_df = energia_por_fecha.pivot(index='LLAVE NOMBRE', columns='FECHA', values='TOTAL').fillna(0)\n",
    "\n",
    "# Convertir las columnas de fecha a datetime\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns)\n",
    "\n",
    "# Añadir la columna de nombres de generadoras al DataFrame\n",
    "pivot_df['LLAVE NOMBRE'] = pivot_df.index\n",
    "\n",
    "# Muestreo: seleccionar una fracción aleatoria de los datos (por ejemplo, el 10%)\n",
    "sample_df = pivot_df.sample(frac=1, random_state=0)  # Ajusta la fracción según sea necesario\n",
    "\n",
    "# Convertir el DataFrame muestreado a un formato adecuado para DTW\n",
    "data = sample_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "\n",
    "# Normalización específica de series temporales\n",
    "data_normalized = TimeSeriesScalerMinMax().fit_transform(data.reshape((data.shape[0], data.shape[1], 1)))\n",
    "\n",
    "# Empezar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Aplicar K-means usando DTW\n",
    "n_clusters = 6  # Ajusta el número de clusters según sea necesario\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0)\n",
    "labels = model.fit_predict(data_normalized)\n",
    "\n",
    "# Añadir los resultados al DataFrame muestreado\n",
    "sample_df['Cluster'] = labels\n",
    "\n",
    "# Reordenar las columnas para mantener 'LLAVE NOMBRE' al principio\n",
    "sample_df = sample_df[['LLAVE NOMBRE', 'Cluster'] + [col for col in sample_df.columns if col not in ['LLAVE NOMBRE', 'Cluster']]]\n",
    "\n",
    "# Calcular la matriz de distancias DTW usando cdist_dtw de manera eficiente\n",
    "distances = cdist_dtw(data_normalized)\n",
    "\n",
    "# Asegurarse de que la diagonal de la matriz sea cero\n",
    "np.fill_diagonal(distances, 0)\n",
    "\n",
    "# Calcular el índice de Silueta usando la matriz precomputada\n",
    "silhouette_avg = silhouette_score(distances, labels, metric='precomputed')\n",
    "\n",
    "# Detener el cronómetro\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
    "print(f\"Tiempo de ejecución: {execution_time / 60:.2f} minutos\")\n",
    "print(f\"Índice de Silueta: {silhouette_avg:.2f}\")\n",
    "\n",
    "# Limpiar las columnas de `pivot_df` asegurándose de que sean fechas\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns, errors='coerce')\n",
    "\n",
    "# Eliminar columnas que no se pudieron convertir a fechas\n",
    "pivot_df = pivot_df.loc[:, pivot_df.columns.notna()]\n",
    "\n",
    "# Obtener la lista de clusters únicos\n",
    "clusters = sample_df['Cluster'].unique()\n",
    "\n",
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'TIPO' de df\n",
    "tipo_df = df[['LLAVE NOMBRE', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de tipos por cluster\n",
    "totales_cluster = {}\n",
    "porcentaje_tipo_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada tipo\n",
    "total_tipos_df = tipo_df['TIPO'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_tipos_df.columns = ['TIPO', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener el tipo correspondiente para cada generadora\n",
    "    tipos = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada tipo\n",
    "    tipo_counts = tipos['TIPO'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = tipo_counts.sum()\n",
    "    totales_cluster[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada tipo dentro del cluster y agregar el conteo\n",
    "    tipo_porcentaje_y_cantidad = tipo_counts.to_frame(name='Cantidad')\n",
    "    tipo_porcentaje_y_cantidad['Porcentaje'] = (tipo_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_tipo_total[cluster] = tipo_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por tipo y por cluster\n",
    "print(\"Proporción total de cada tipo de generadora:\")\n",
    "print(total_tipos_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster:\")\n",
    "for cluster, total in totales_cluster.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por tipo en el cluster {cluster}:\")\n",
    "    print(porcentaje_tipo_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad\n",
    "\n",
    "# Calcular las series más cercanas al centroide para cada tipo dentro de cada cluster\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Filtrar las series temporales de las generadoras en el cluster\n",
    "    cluster_series = pivot_df.loc[generadoras]\n",
    "    \n",
    "    # Obtener los tipos de energía en el cluster\n",
    "    tipos_en_cluster = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Iterar sobre cada tipo de energía en el cluster\n",
    "    for tipo in tipos_en_cluster['TIPO'].unique():\n",
    "        # Filtrar las series temporales del tipo de energía actual\n",
    "        series_tipo = cluster_series.loc[tipos_en_cluster[tipos_en_cluster['TIPO'] == tipo]['LLAVE NOMBRE']]\n",
    "        \n",
    "        if not series_tipo.empty:\n",
    "            # Calcular el centroide (media) del tipo de energía\n",
    "            centroide = series_tipo.mean(axis=0)\n",
    "            \n",
    "            # Calcular la distancia entre cada serie temporal y el centroide usando la distancia euclidiana\n",
    "            distancias = np.array([np.linalg.norm(centroide.values - serie.values) for index, serie in series_tipo.iterrows()]).reshape(-1, 1)\n",
    "            \n",
    "            # Encontrar las 3 series más cercanas al centroide\n",
    "            indices_mas_cercanas = np.argsort(distancias, axis=0)[:3].flatten()\n",
    "            series_representativas = series_tipo.iloc[indices_mas_cercanas]\n",
    "            \n",
    "            # Graficar las 3 series temporales representativas\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            for j, (index, serie) in enumerate(series_representativas.iterrows()):\n",
    "                ax.plot(pivot_df.columns, serie, label=f'Cluster {cluster} - Tipo {tipo} - Serie {j+1}', linestyle='-', marker='o')\n",
    "            \n",
    "            # Configuración del gráfico\n",
    "            ax.set_title(f'Series Temporales Representativas del Cluster {cluster} - Tipo {tipo}')\n",
    "            ax.set_xlabel('Fecha')\n",
    "            ax.set_ylabel('Valor')\n",
    "            ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from tslearn.preprocessing import TimeSeriesScalerMinMax\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.metrics import cdist_dtw\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "\n",
    "# Agrupar por fecha y llave, y sumar la columna 'TOTAL'\n",
    "energia_por_fecha = df.groupby(['LLAVE NOMBRE', 'FECHA'])['TOTAL'].sum().reset_index()\n",
    "\n",
    "# Pivotar los datos para tener fechas como columnas y llaves como filas\n",
    "pivot_df = energia_por_fecha.pivot(index='LLAVE NOMBRE', columns='FECHA', values='TOTAL').fillna(0)\n",
    "\n",
    "# Convertir las columnas de fecha a datetime\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns)\n",
    "\n",
    "# Añadir la columna de nombres de generadoras al DataFrame\n",
    "pivot_df['LLAVE NOMBRE'] = pivot_df.index\n",
    "\n",
    "# Muestreo: seleccionar una fracción aleatoria de los datos (por ejemplo, el 10%)\n",
    "sample_df = pivot_df.sample(frac=1, random_state=0)  # Ajusta la fracción según sea necesario\n",
    "\n",
    "# Convertir el DataFrame muestreado a un formato adecuado para DTW\n",
    "data = sample_df.drop(columns=['LLAVE NOMBRE']).values\n",
    "\n",
    "# Normalización específica de series temporales\n",
    "data_normalized = TimeSeriesScalerMinMax().fit_transform(data.reshape((data.shape[0], data.shape[1], 1)))\n",
    "\n",
    "# Empezar el cronómetro\n",
    "start_time = time.time()\n",
    "\n",
    "# Aplicar K-means usando DTW\n",
    "n_clusters = 6  # Ajusta el número de clusters según sea necesario\n",
    "model = TimeSeriesKMeans(n_clusters=n_clusters, metric=\"dtw\", random_state=0)\n",
    "labels = model.fit_predict(data_normalized)\n",
    "\n",
    "# Añadir los resultados al DataFrame muestreado\n",
    "sample_df['Cluster'] = labels\n",
    "\n",
    "# Reordenar las columnas para mantener 'LLAVE NOMBRE' al principio\n",
    "sample_df = sample_df[['LLAVE NOMBRE', 'Cluster'] + [col for col in sample_df.columns if col not in ['LLAVE NOMBRE', 'Cluster']]]\n",
    "\n",
    "# Calcular la matriz de distancias DTW usando cdist_dtw de manera eficiente\n",
    "distances = cdist_dtw(data_normalized)\n",
    "\n",
    "# Asegurarse de que la diagonal de la matriz sea cero\n",
    "np.fill_diagonal(distances, 0)\n",
    "\n",
    "# Calcular el índice de Silueta usando la matriz precomputada\n",
    "silhouette_avg = silhouette_score(distances, labels, metric='precomputed')\n",
    "\n",
    "# Detener el cronómetro\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo de ejecución\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"Tiempo de ejecución: {execution_time:.2f} segundos\")\n",
    "print(f\"Tiempo de ejecución: {execution_time / 60:.2f} minutos\")\n",
    "print(f\"Índice de Silueta: {silhouette_avg:.2f}\")\n",
    "\n",
    "# Visualización de los clústeres usando PCA\n",
    "data_reshaped = data_normalized.reshape(data_normalized.shape[0], -1)  # Convertir a 2D para PCA y t-SNE\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data_reshaped)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in np.unique(labels):\n",
    "    plt.scatter(data_pca[labels == cluster, 0], data_pca[labels == cluster, 1], label=f'Cluster {cluster}')\n",
    "plt.title(\"Visualización de Clústeres usando PCA\")\n",
    "plt.xlabel(\"Componente Principal 1 (Varianza Máxima)\")\n",
    "plt.ylabel(\"Componente Principal 2 (Segunda Mayor Varianza)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualización de los clústeres usando t-SNE con init=\"random\"\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300, random_state=0, metric=\"precomputed\", init=\"random\")\n",
    "data_tsne = tsne.fit_transform(distances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster in np.unique(labels):\n",
    "    plt.scatter(data_tsne[labels == cluster, 0], data_tsne[labels == cluster, 1], label=f'Cluster {cluster}')\n",
    "plt.title(\"Visualización de Clústeres usando t-SNE\")\n",
    "plt.xlabel(\"Componente t-SNE 1\")\n",
    "plt.ylabel(\"Componente t-SNE 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Limpiar las columnas de `pivot_df` asegurándose de que sean fechas\n",
    "pivot_df.columns = pd.to_datetime(pivot_df.columns, errors='coerce')\n",
    "\n",
    "# Eliminar columnas que no se pudieron convertir a fechas\n",
    "pivot_df = pivot_df.loc[:, pivot_df.columns.notna()]\n",
    "\n",
    "# Obtener la lista de clusters únicos\n",
    "clusters = sample_df['Cluster'].unique()\n",
    "\n",
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'TIPO' de df\n",
    "tipo_df = df[['LLAVE NOMBRE', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de tipos por cluster\n",
    "totales_cluster = {}\n",
    "porcentaje_tipo_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada tipo\n",
    "total_tipos_df = tipo_df['TIPO'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_tipos_df.columns = ['TIPO', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener el tipo correspondiente para cada generadora\n",
    "    tipos = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada tipo\n",
    "    tipo_counts = tipos['TIPO'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = tipo_counts.sum()\n",
    "    totales_cluster[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada tipo dentro del cluster y agregar el conteo\n",
    "    tipo_porcentaje_y_cantidad = tipo_counts.to_frame(name='Cantidad')\n",
    "    tipo_porcentaje_y_cantidad['Porcentaje'] = (tipo_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_tipo_total[cluster] = tipo_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por tipo y por cluster\n",
    "print(\"Proporción total de cada tipo de generadora:\")\n",
    "print(total_tipos_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster:\")\n",
    "for cluster, total in totales_cluster.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por tipo en el cluster {cluster}:\")\n",
    "    print(porcentaje_tipo_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad\n",
    "\n",
    "# Calcular las series más cercanas al centroide para cada tipo dentro de cada cluster\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Filtrar las series temporales de las generadoras en el cluster\n",
    "    cluster_series = pivot_df.loc[generadoras]\n",
    "    \n",
    "    # Obtener los tipos de energía en el cluster\n",
    "    tipos_en_cluster = tipo_df[tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Iterar sobre cada tipo de energía en el cluster\n",
    "    for tipo in tipos_en_cluster['TIPO'].unique():\n",
    "        # Filtrar las series temporales del tipo de energía actual\n",
    "        series_tipo = cluster_series.loc[tipos_en_cluster[tipos_en_cluster['TIPO'] == tipo]['LLAVE NOMBRE']]\n",
    "        \n",
    "        if not series_tipo.empty:\n",
    "            # Calcular el centroide (media) del tipo de energía\n",
    "            centroide = series_tipo.mean(axis=0)\n",
    "            \n",
    "            # Calcular la distancia entre cada serie temporal y el centroide usando la distancia euclidiana\n",
    "            distancias = np.array([np.linalg.norm(centroide.values - serie.values) for index, serie in series_tipo.iterrows()]).reshape(-1, 1)\n",
    "            \n",
    "            # Encontrar las 3 series más cercanas al centroide\n",
    "            indices_mas_cercanas = np.argsort(distancias, axis=0)[:3].flatten()\n",
    "            series_representativas = series_tipo.iloc[indices_mas_cercanas]\n",
    "            \n",
    "            # Graficar las 3 series temporales representativas\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            for j, (index, serie) in enumerate(series_representativas.iterrows()):\n",
    "                ax.plot(pivot_df.columns, serie, label=f'Cluster {cluster} - Tipo {tipo} - Serie {j+1}', linestyle='-', marker='o')\n",
    "            \n",
    "            # Configuración del gráfico\n",
    "            ax.set_title(f'Series Temporales Representativas del Cluster {cluster} - Tipo {tipo}')\n",
    "            ax.set_xlabel('Fecha')\n",
    "            ax.set_ylabel('Valor')\n",
    "            ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031800a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un DataFrame con la columna 'LLAVE NOMBRE' y 'REGIÓN' de df\n",
    "region_df = df[['LLAVE NOMBRE', 'REGIÓN']].drop_duplicates()\n",
    "\n",
    "# Crear un diccionario para almacenar los totales y proporciones de regiones por cluster\n",
    "totales_cluster_region = {}\n",
    "porcentaje_region_total = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada región\n",
    "total_regiones_df = region_df['REGIÓN'].value_counts().to_frame(name='Total').reset_index()\n",
    "total_regiones_df.columns = ['REGIÓN', 'Total']\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener la región correspondiente para cada generadora\n",
    "    regiones = region_df[region_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada región\n",
    "    region_counts = regiones['REGIÓN'].value_counts()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = region_counts.sum()\n",
    "    totales_cluster_region[cluster] = total_cluster\n",
    "    \n",
    "    # Calcular el porcentaje de cada región dentro del cluster y agregar el conteo\n",
    "    region_porcentaje_y_cantidad = region_counts.to_frame(name='Cantidad')\n",
    "    region_porcentaje_y_cantidad['Porcentaje'] = (region_counts / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los porcentajes y cantidades en el diccionario\n",
    "    porcentaje_region_total[cluster] = region_porcentaje_y_cantidad\n",
    "\n",
    "# Mostrar los resultados totales por región y por cluster\n",
    "print(\"Proporción total de cada región de generadora:\")\n",
    "print(total_regiones_df)\n",
    "print()\n",
    "\n",
    "print(\"Totales, cantidades y porcentajes de cada cluster por región:\")\n",
    "for cluster, total in totales_cluster_region.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras: {total}\")\n",
    "    print(f\"Cantidad y porcentaje por región en el cluster {cluster}:\")\n",
    "    print(porcentaje_region_total[cluster])\n",
    "    print()  # Línea en blanco para mayor legibilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de83f46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las columnas 'LLAVE NOMBRE', 'REGIÓN' y 'TIPO' de df, eliminando duplicados\n",
    "region_tipo_df = df[['LLAVE NOMBRE', 'REGIÓN', 'TIPO']].drop_duplicates()\n",
    "\n",
    "# Diccionario para almacenar los totales y proporciones de tipos por región y cluster\n",
    "totales_cluster_region_tipo = {}\n",
    "\n",
    "# Inicializar un DataFrame para acumular el total de cada región y tipo\n",
    "total_regiones_df = region_tipo_df.groupby(['REGIÓN', 'TIPO']).size().to_frame(name='Total').reset_index()\n",
    "\n",
    "# Iterar sobre cada cluster para calcular los totales y proporciones por región y tipo\n",
    "for cluster in clusters:\n",
    "    # Filtrar los datos del cluster\n",
    "    cluster_data = sample_df[sample_df['Cluster'] == cluster]\n",
    "    \n",
    "    # Obtener la lista de generadoras en el cluster\n",
    "    generadoras = cluster_data['LLAVE NOMBRE'].unique()\n",
    "    \n",
    "    # Obtener la región y tipo correspondiente para cada generadora\n",
    "    regiones_tipos = region_tipo_df[region_tipo_df['LLAVE NOMBRE'].isin(generadoras)]\n",
    "    \n",
    "    # Contar las ocurrencias de cada combinación de región y tipo\n",
    "    region_tipo_counts = regiones_tipos.groupby(['REGIÓN', 'TIPO']).size().to_frame(name='Cantidad').reset_index()\n",
    "    \n",
    "    # Guardar el total de generadoras en el cluster\n",
    "    total_cluster = region_tipo_counts['Cantidad'].sum()\n",
    "    \n",
    "    # Calcular el porcentaje de cada combinación de región y tipo dentro del cluster\n",
    "    region_tipo_counts['Porcentaje'] = (region_tipo_counts['Cantidad'] / total_cluster) * 100\n",
    "    \n",
    "    # Almacenar los resultados en el diccionario\n",
    "    totales_cluster_region_tipo[cluster] = region_tipo_counts\n",
    "\n",
    "# Mostrar los resultados totales por región y tipo en cada cluster\n",
    "print(\"Totales, cantidades y porcentajes de cada combinación de región y tipo por cluster:\")\n",
    "for cluster, data in totales_cluster_region_tipo.items():\n",
    "    print(f\"Cluster {cluster} - Total generadoras:\")\n",
    "    print(data)\n",
    "    print()  # Línea en blanco para mayor legibilidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a23bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
